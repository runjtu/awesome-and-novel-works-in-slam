# awesome-and-novel-works-in-slam [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

This repo contains a mostly curative (new derives from old) list of **novel and useful works in slam** <br>

If you find this repository useful, please consider STARing this list. Feel free to share this list with others!

---
## Overview

  - [NeRF](#nerf)
  - [v2x](#v2x)
  - [Semantic](#semantic)
  - [novelcv](#novelcv)
  - [Largemodel](#largemodel)
  - [leaders](#leaders)

---

## NeRF
* **Gaussian Splatting**: "3D Gaussian Splatting for Real-Time Radiance Field Rendering", *ACM Transactions on Graphics 2023*.  [[Paper](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)] [[Code](https://github.com/graphdeco-inria/gaussian-splatting)]

* **Neural-Sim**: "Learning to Generate Training Data with NeRF", *ECCV 2022*.  [[Paper](https://arxiv.org/pdf/2207.11368.pdf)] [[Code](https://github.com/gyhandy/Neural-Sim-NeRF)] [[Webpage](https://fylwen.github.io/disp6d.html)]


* **iNeRF**: "Inverting Neural Radiance Fields for Pose Estimation", *IROS, 2021*. [[Paper](https://arxiv.org/pdf/2012.05877.pdf)] [[Code](https://github.com/yenchenlin/iNeRF-public)] [[Website](https://yenchenlin.me/inerf/)] [[Dataset](https://github.com/BerkeleyAutomation/dex-nerf-datasets)]

* **iMAP**: "Implicit Mapping and Positioning in Real-Time", *ICCV, 2021*. [[Paper](https://arxiv.org/abs/2103.12352)] [[Code](https://edgarsucar.github.io/iMAP/)]

* **SHINE-Mapping**: "Large-Scale 3D Mapping Using Sparse Hierarchical Implicit Neural Representations", *ICRA, 2023*. [[Paper](https://arxiv.org/pdf/2210.02299.pdf)] [[Code](https://github.com/PRBonn/SHINE_mapping)]

* **H2-Mapping**: "Real-time Dense Mapping Using Hierarchical Hybrid Representation", *RA-L, 2023*. [[Paper](https://arxiv.org/pdf/2306.03207.pdf)] [[Code](https://github.com/SYSU-STAR/H2-Mapping)]

* **LATITUDE**: Robotic Global Localization with Truncated Dynamic Low-pass Filter in City-scale NeRF, *ICRA,  2023*. [[Paper](https://arxiv.org/pdf/2209.09357.pdf)] [[Code](https://github.com/jike5/LATITUDE)]


* **NeuSE**: "Neural SE(3)-Equivariant Embedding for Consistent Spatial Understanding with Objects", *arXiv*. [[Paper](https://arxiv.org/pdf/2303.07308.pdf)] [[Code](https://neuse-slam.github.io/neuse/)]

* **ObjectFusion**: "Accurate object-level SLAM with neural object priors", *Graphical Models,  2022*. [[Paper](https://www.sciencedirect.com/science/article/pii/S1524070322000418)]

* **NDF_Change**: "Robust Change Detection Based on Neural Descriptor Fields", *IROS, 2022*. [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9981246)]

* **LNDF**: "Local Neural Descriptor Fields: Locally Conditioned Object Representations for Manipulation", *ICRA, 2023*. [[Paper](https://arxiv.org/abs/2302.03573)] [[Webpage](https://elchun.github.io/lndf/)]

- **NeRF-LOAM**: Neural Implicit Representation for Large-Scale Incremental LiDAR Odometry and Mapping, *arXiv*. [[Paper](https://arxiv.org/pdf/2303.10709.pdf)] [[Code](https://github.com/JunyuanDeng/NeRF-LOAM)]

* "Implicit Map Augmentation for Relocalization", *ECCV Workshop, 2022*. [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-25066-8_36)]

*  **Co-SLAM**: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM, *CVPR, 2023*. [[Paper](https://arxiv.org/pdf/2304.14377.pdf)] [[Website](https://hengyiwang.github.io/projects/CoSLAM)]
*  Neural Implicit Dense Semantic SLAM, *arXiv, 2023*. [[Paper](https://arxiv.org/pdf/2304.14560.pdf)]

* **NeRF-Navigation**: "Vision-Only Robot Navigation in a Neural Radiance World", *ICRA, 2022*. [[Paper](https://mikh3x4.github.io/nerf-navigation/assets/NeRF_Navigation.pdf)] [[Code](https://github.com/mikh3x4/nerf-navigation)] [[Website](https://mikh3x4.github.io/nerf-navigation/)] 


* **ESDF**: "Sampling-free obstacle gradients and reactive planning in Neural Radiance Fields", *arXiv*. [[Paper](https://arxiv.org/abs/2205.01389)]

---
## v2x

* **HighwayEnv**: "An Environment for Autonomous Driving Decision-Making", *GitHub*. [[Code](https://github.com/Farama-Foundation/HighwayEnv)]

* **OpenLane-V2**: "The World's First Perception and Reasoning Benchmark for Scene Structure in Autonomous Driving.", *GitHub*. [[Code](https://github.com/OpenDriveLab/OpenLane-V2)]



---
## semantic

* **OPen3d**: "A Modern Library for 3D Data Processing", *arxiv*. [[Paper](https://arxiv.org/abs/1801.09847)] [[Code](https://github.com/isl-org/Open3D-ML)]


---
## novelcv

* **UniDistill**: "A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View", *Github*. [[Code](https://github.com/megvii-research/CVPR2023-UniDistill)]


---
## largemodel

* **DriveLikeAHuman**: "Rethinking Autonomous Driving with Large Language Models", *CVPR, 2023*. [[Code](https://github.com/PJLab-ADG/DriveLikeAHuman)]



----
## leaders

Industries

* **NVlabs** [[Homepage](https://github.com/NVlabs)]

* **NVIDIA Isaac** [[Homepage](https://github.com/nvidia-isaac)]

* **nROS-Lab** [[Homepage](https://github.com/HITSZ-NRSL)]

* **qcraftai** [[Homepage](https://github.com/qcraftai)]

* **Motional** [[Homepage](https://github.com/nutonomy)]

* **valeo.ai** [[Homepage](https://github.com/valeoai)]

* **livox** [[Homepage](https://github.com/Livox-SDK)]

* **ROS-device-drivers** [[Homepage](https://github.com/ros-drivers)]

* **Open Robotics** [[Homepage](https://github.com/osrf)]

* **ADG@PJLab** [[Homepage](https://github.com/PJLab-ADG)]

Europe 

* **University of Tübingen** [[Homepage](https://github.com/autonomousvision)]

* **University of Oxford Control Group** [[Homepage](https://github.com/oxfordcontrol)]

* **wayveai** [[Homepage](https://github.com/wayveai)]

* **ETH Robotic Systems Lab** [[Homepage](https://github.com/leggedrobotics)]

* **NMBURobotics** [[Homepage](https://github.com/NMBURobotics)]

* **BORG Lab** [[Homepage](https://github.com/borglab)]

* **Photogrammetry-Robotics-Bonn** [[Homepage](https://github.com/PRBonn)]

* **ETHZ-ASL** [[Homepage](https://github.com/ethz-asl)]

* **Visual Intelligence and Systems Group at ETH Zürich** [[Homepage](https://github.com/SysCV)]

* **Oxford Dynamic Robot Systems Group** [[Homepage](https://github.com/ori-drs)]

* **TIERS** [[Homepage](https://github.com/TIERS)]

* **ANYbotics** [[Homepage](https://github.com/ANYbotics)]

* **TUM-Institue-of-Auotomative-Technology** [[Homepage](https://github.com/TUMFTM)]

* **TUM-Computer-Vision-Group** [[Homepage](https://github.com/tum-vision)]

* **TUM Smart Robotics Lab** [[Homepage](https://github.com/smartroboticslab)]

* **UFR Robot Learning** [[Homepage](https://github.com/robot-learning-freiburg)]

* **Institute of Measurement and Control Systems at the Karlsruhe Institute of Technology** [[Homepage](https://github.com/KIT-MRT)]

* **Institute of Automatic Control RWTH Aachen University** [[Homepage](https://github.com/rwth-irt)]

* **Computer-Vision-and-Geometry-Lab** [[Homepage](https://github.com/cvg)]

America

* **MIT-SPARKs** [[Homepage](https://github.com/MIT-SPARK)]

* **Virginia Tech Transportation Institute** [[Homepage](https://github.com/VTTI)]

* **OpenDriveLab** [[Homepage](https://github.com/OpenDriveLab)]

* **Open Source software from the AirLab (Robotics Institute, Carnegie Mellon University)** [[Homepage](https://github.com/castacks)]

* **princeton-computational-imaging** [[Homepage](https://github.com/princeton-computational-imaging)]

* **UCSD Existential Robotics Lab** [[Homepage](https://github.com/ExistentialRobotics)]

* **Umich The Autonomous Robotic Manipulation Lab studies motion planning, manipulation, and human-robot collaboration** [[Homepage](https://github.com/UM-ARM-Lab)]

* **University of Michigan Dynamic Legged Locomotion Robotics Lab** [[Homepage](https://github.com/UMich-BipedLab)]

* **CL2-UWaterloo** [[Homepage](https://github.com/CL2-UWaterloo)]

* **AI4CE Lab @ NYU** [[Homepage](https://github.com/ai4ce)]

* **University of British Columbia Computer Vision Group** [[Homepage](https://github.com/ubc-vision)]

Asia

* **Japan National Institute of Advanced Industrial Science and Technology** [[Homepage](https://github.com/SMRT-AIST)]

* **ZJU Advanced-Perception-on-Robotics-and-Intelligent-Learning-Lab** [[Homepage](https://github.com/APRIL-ZJU)]

* **ZJU 3DV** [[Homepage](https://github.com/zju3dv)]

* **HKU Mars Lab** [[Homepage](https://github.com/hku-mars)]

* **Visual Learning and Reasoning Group HK PolyU** [[Homepage](https://github.com/vLAR-group)]

* **Audio Signal and Information Processing Lab at Westlake University** [[Homepage](https://github.com/Audio-WestlakeU)]

* **Wuhan University Urban Spatial Intelligence Research Group at LIESMARS** [[Homepage](https://github.com/WHU-USI3DV)]

* **Integrated and Intelligent Navigation Group, Wuhan University** [[Homepage](https://github.com/i2Nav-WHU)]

* **SYSU-RAPID-Lab** [[Homepage](https://github.com/SYSU-RoboticsLab)]

* **SYSU Pengyu Team** [[Homepage](https://github.com/PengYu-Team)]

* **ShanghaiTech Vision and Intelligent Perception Lab** [[Homepage](https://github.com/svip-lab)]

----
